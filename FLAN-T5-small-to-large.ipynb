{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870e8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677130fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"Complete_dataset/test.json\"))\n",
    "files = os.listdir(\"Complete_dataset/CT json/\")\n",
    "files.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5df4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_data = {file[:-5]:json.load(open(f\"Complete_dataset/CT json/{file}\")) for file in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07636837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_expanded = []\n",
    "for _id, value in data.items():\n",
    "    temp = {}\n",
    "    temp[\"id\"] = _id\n",
    "    p_nctid = value[\"Primary_id\"]\n",
    "    s_nctid = value.get(\"Secondary_id\")\n",
    "    section_id = value[\"Section_id\"]\n",
    "    statement = value[\"Statement\"]\n",
    "    primary_evidence = files_data[p_nctid][section_id]\n",
    "    temp[\"statement\"] = statement\n",
    "    temp[\"primary_evidence\"] = primary_evidence\n",
    "    # temp[\"label\"] = value[\"Label\"]\n",
    "    \n",
    "    if s_nctid is not None:\n",
    "        secondary_evidence = files_data[s_nctid][section_id]\n",
    "        temp[\"secondary_evidence\"] = secondary_evidence\n",
    "    \n",
    "    data_expanded.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08499f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_text(premise, hypothesis):\n",
    "    options_prefix = \"OPTIONS:\\n- \"\n",
    "    separator = \"\\n- \"\n",
    "    options_ = options_prefix + f\"{separator}\".join([\"Entailment\",\"Contradiction\"])\n",
    "    return f\"{premise} \\n Question: Does this imply that {hypothesis}? {options_}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19adb80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for sample in data_expanded:\n",
    "    primary_evidence = \"\".join([x.strip() for x in sample['primary_evidence']])\n",
    "    sentence = f\"Primary trial evidence are {primary_evidence}\"\n",
    "    secondary_evidence = sample.get(\"secondary_evidence\")\n",
    "    if secondary_evidence:\n",
    "        secondary_evidence = \"\".join([x.strip() for x in sample['secondary_evidence']])\n",
    "        sentence = f\"{sentence} Secondary trial evidence are {secondary_evidence}\"\n",
    "    input_text = get_input_text(sentence, sample['statement'])\n",
    "    temp = {\"text\":input_text, \"label\":0}\n",
    "    samples.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7d4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce56a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/kamal_raj/transformers/src/transformers/generation/utils.py:1234: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "  1%|          | 3/500 [00:01<03:39,  2.26it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 500/500 [01:26<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Contradiction': 374, 'Entailment': 126})\n",
      "updating: results.json (deflated 74%)\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['large']:#,'base','large']:\n",
    "    # tokenizer = T5Tokenizer.from_pretrained(f\"google/flan-t5-{model_name}\",cache_dir=\"/mnt/data/huggingface_cache\", )\n",
    "    # model = T5ForConditionalGeneration.from_pretrained(f\"google/flan-t5-{model_name}\", cache_dir=\"/mnt/data/huggingface_cache\", device_map=\"auto\",torch_dtype=torch.float16)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(f\"output_dir_{model_name}\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(f\"output_dir_{model_name}\", device_map=\"auto\",torch_dtype=torch.float16)\n",
    "    labels = []\n",
    "    pred = []\n",
    "    with torch.inference_mode():\n",
    "        for sample in tqdm.tqdm(samples):\n",
    "            labels.append(sample[\"label\"])\n",
    "            input_ids = tokenizer(sample[\"text\"], return_tensors=\"pt\",).input_ids.to(\"cuda\")\n",
    "            outputs = model.generate(input_ids)\n",
    "            pred.append(tokenizer.decode(outputs[0]))\n",
    "    \n",
    "    pred = [p[5:][:-4].strip() for p in pred]\n",
    "    print(Counter(pred))\n",
    "    prediction_dict = {}\n",
    "    for _id,pred_x in zip(data, pred):\n",
    "        if pred_x.lower() == \"no\":\n",
    "            pred_x = \"Contradiction\"\n",
    "        elif pred_x.lower() == \"yes\":\n",
    "            pred_x = \"Entailment\"\n",
    "        # else:\n",
    "        #     print(pred_x)\n",
    "        prediction_dict[str(_id)] = {\"Prediction\":pred_x}\n",
    "    \n",
    "    json.dump(prediction_dict, open(\"results.json\",'w'),indent=4)\n",
    "    !zip \"small_large/results_{model_name}.zip\" results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb51ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cf230bfe48388054af6957fef277c9681be8115aa3a1a86509ea0819612252f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
